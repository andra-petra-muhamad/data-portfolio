{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "khsuxDLIoIrs"
   },
   "source": [
    "# Machine Translation with Transformer\n",
    "Machine translation is a key milestone in the development of Natural Language Processing (NLP). The Transformer model, introduced by Vaswani et al. (2017), was a major revolution because it replaced RNN and CNN-based architectures with a more efficient attention mechanism.\n",
    "\n",
    "In this notebook, we will build a Transformer model from scratch to automatically translate from English to Spanish. This approach does not use a pre-trained model, but instead implements the core components of the Transformer, from positional encoding, multi-head attention, encoder-decoder layers, to the training process.\n",
    "\n",
    "The main focus is not only on the translation results, but also on the implementation capabilities and understanding of the Transformer's internal mechanisms. This is relevant because the Transformer is the foundation of various modern models such as BERT, GPT, and ChatGPT, making mastering its basic architecture essential for both Machine Learning Engineers and Data Scientists.\n",
    "\n",
    "The dataset source is www.manythings.org/anki\n",
    "\n",
    "## Sequence-to-sequence learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fZ98ptbtoRii"
   },
   "source": [
    "### Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "3cJAoIeTXqIx"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pathlib\n",
    "import random\n",
    "import string\n",
    "import zipfile\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import TextVectorization\n",
    "from tensorflow.keras.layers import Bidirectional,GRU,LSTM,Embedding\n",
    "from tensorflow.keras.layers import Dense,MultiHeadAttention,LayerNormalization,Embedding,Dropout,Layer\n",
    "from tensorflow.keras import Sequential,Input\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ps4nkpcHoW7D"
   },
   "source": [
    "### Download and Extract Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download ZIP (no auto-extract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_zip = keras.utils.get_file(\n",
    "    \"spa-eng.zip\",\n",
    "    origin=\"http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip\",\n",
    "    extract=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Manual extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with zipfile.ZipFile(path_to_zip, 'r') as zip_ref:\n",
    "    zip_ref.extractall(pathlib.Path(path_to_zip).parent)\n",
    "\n",
    "text_file = pathlib.Path(path_to_zip).parent / \"spa-eng\" / \"spa.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### View all extracted files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(text_file, encoding=\"utf-8\") as f:\n",
    "    lines = f.read().split(\"\\n\")[:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PIWHVxF-oZfa"
   },
   "source": [
    "### Prepare Text Pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NR4qXBuAp6TN"
   },
   "source": [
    "Each line contains an English sentence and a corresponding Spanish sentence. The English sentence is the source sequence, and the Spanish sentence is the target sequence. We add a \"[start]\" token at the front and an \"[end]\" token at the end of the Spanish sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "8XXQjzxlXxBq"
   },
   "outputs": [],
   "source": [
    "# Start and end indicate when the translation of the word/phrase starts and stops.\n",
    "\n",
    "text_pairs = []\n",
    "for line in lines:\n",
    "    english, spanish = line.split(\"\\t\")\n",
    "    spanish = \"[start] \" + spanish + \" [end]\"\n",
    "    text_pairs.append((english, spanish))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YNV4qYbApu7K",
    "outputId": "45f01629-6967-4414-f0c9-b1356daaf5ae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of pairs: 118964\n",
      "Example text: (\"I'll be fine.\", '[start] Estaré bien. [end]')\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of pairs:\", len(text_pairs))\n",
    "print(\"Example text:\", text_pairs[2900])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "McidSg9oqA5e"
   },
   "source": [
    "Printing random text pairs English - Spanish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dau5SsHEqDt2",
    "outputId": "b03c8b10-fffe-46c8-e942-c54411c4875c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Where can I buy envelopes?', '[start] ¿Dónde puedo comprar sobres? [end]')\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "print(random.choice(text_pairs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pUOejgj9ob6C"
   },
   "source": [
    "### Split Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LOtPnpe-qL-0"
   },
   "source": [
    "- train_pairs: initial 70% of the data\n",
    "- val_pairs: next 15%\n",
    "- test_pairs: last 15%\n",
    "- 70% training: large enough to learn patterns.\n",
    "- 15% validation: sufficient for hyperparameter tuning.\n",
    "- 15% test: sufficient to measure the model's generalization performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Determine the amount of validation data 15% of the total data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(text_pairs)\n",
    "\n",
    "num_val_samples = int(0.15 * len(text_pairs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Taking the remaining data for training, after setting aside 15% for validation and 15% for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "8aMQvgqjXzre"
   },
   "outputs": [],
   "source": [
    "num_train_samples = len(text_pairs) - 2 * num_val_samples\n",
    "train_pairs = text_pairs[:num_train_samples]\n",
    "val_pairs = text_pairs[num_train_samples:num_train_samples + num_val_samples]\n",
    "test_pairs = text_pairs[num_train_samples + num_val_samples:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ymKGiQPLqOF1",
    "outputId": "b2a6b9a3-0e88-4d90-8583-20c3a3d3a2a4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train data: 83276\n",
      "Number of validation data: 17844\n",
      "Number of test data: 17844\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of train data:\", len(train_pairs))\n",
    "print(\"Number of validation data:\", len(val_pairs))\n",
    "print(\"Number of test data:\", len(test_pairs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k8wh2_Ahoe-S"
   },
   "source": [
    "### Preprocessing and Vectorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Otldv3LkqiUO"
   },
   "source": [
    "* string.punctuation is a Python built-in that contains all common punctuation characters.\n",
    "* Added + \"¿\" because the \"¿\" (inverted question mark) symbol is the opening question mark in Spanish (e.g., ¿Cómo estás?).\n",
    "* Creates a list of all characters considered \"punctuation to be removed or cleared from the text.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "0-7VqsMGqkrM"
   },
   "outputs": [],
   "source": [
    "def custom_standardization(input_string):\n",
    "    lowercase = tf.strings.lower(input_string)\n",
    "    return tf.strings.regex_replace(lowercase, f\"[{re.escape(string.punctuation)}¿]\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "doKPFLU8qnHy"
   },
   "outputs": [],
   "source": [
    "vocab_size = 15000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means that only the 15,000 most frequently occurring words will be used in the dictionary (vocab). Next, determine the maximum length of the token sequence after the text is tokenized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_length = 20 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VWkolLapqxD-"
   },
   "source": [
    "* Vectorizes input (English)\n",
    "* Used for encoders, which only need plain text sequences (without special tokens like [start] / [end])."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "tWaJKgRwqyc0"
   },
   "outputs": [],
   "source": [
    "source_vectorization = layers.TextVectorization(\n",
    "    max_tokens=vocab_size,\n",
    "    output_mode=\"int\",\n",
    "    output_sequence_length=sequence_length,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "88rmdmeqq1M1"
   },
   "source": [
    "* Vectorizes the target (Spanish)\n",
    "* output_sequence_length=20: Since the target has [start] and [end] tokens, the target is 1 token longer than the input.\n",
    "* standardize=custom_standardization: Uses a custom text cleaning function (e.g., removes certain punctuation but keeps [start] and [end])."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "_jiWvg3SX2DK"
   },
   "outputs": [],
   "source": [
    "target_vectorization = layers.TextVectorization(\n",
    "    max_tokens=vocab_size,\n",
    "    output_mode=\"int\",\n",
    "    output_sequence_length=sequence_length + 1,\n",
    "    standardize=custom_standardization,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract all English sentences from training data pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_english_texts = [pair[0] for pair in train_pairs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract all Spanish sentences (with [start] and [end])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_spanish_texts = [pair[1] for pair in train_pairs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the TextVectorization layer to build a vocabulary based on the training text.\n",
    "`.adapt()` is essential for vectorization to recognize common words and efficiently construct the vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "FfrvQO_cq4ud"
   },
   "outputs": [],
   "source": [
    "source_vectorization.adapt(train_english_texts)\n",
    "target_vectorization.adapt(train_spanish_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h8Ow3sX6oiMk"
   },
   "source": [
    "### Dataset Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Meaning: The model will process 64 sentence pairs (English–Spanish) in one step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "eSuhef1WX4FO"
   },
   "outputs": [],
   "source": [
    "def format_dataset(eng, spa):\n",
    "    eng = source_vectorization(eng) # Input tokenization (English)\n",
    "    spa = target_vectorization(spa) # Target tokenization (Spanish)\n",
    "    return ({\"english\": eng, \"spanish\": spa[:, :-1]}, spa[:, 1:])\n",
    "    # All target tokens EXCEPT the last or EXCEPT the first\n",
    "\n",
    "def make_dataset(pairs):\n",
    "    # Separate the pairs (eng, spa) into 2 lists\n",
    "    eng_texts, spa_texts = zip(*pairs) \n",
    "    \n",
    "    # Create a tf.data.Dataset from text pairs\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((list(eng_texts), list(spa_texts)))\n",
    "    dataset = dataset.batch(batch_size) # Split data into batches of size 64\n",
    "    dataset = dataset.map(format_dataset, num_parallel_calls=tf.data.AUTOTUNE) # Batch content format with dataset format\n",
    "    return dataset.shuffle(2048).prefetch(tf.data.AUTOTUNE).cache() # Store the transformed data in memory for efficiency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = make_dataset(train_pairs)\n",
    "val_ds = make_dataset(val_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9EXsSyv-rgWa",
    "outputId": "f2809091-2efd-44cd-8e59-ce44f0f17e2b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<CacheDataset element_spec=({'english': TensorSpec(shape=(None, 20), dtype=tf.int64, name=None), 'spanish': TensorSpec(shape=(None, 20), dtype=tf.int64, name=None)}, TensorSpec(shape=(None, 20), dtype=tf.int64, name=None))>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ery4gUVhrhut",
    "outputId": "3f44baeb-991d-417d-8d36-863a23fd7b07"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<CacheDataset element_spec=({'english': TensorSpec(shape=(None, 20), dtype=tf.int64, name=None), 'spanish': TensorSpec(shape=(None, 20), dtype=tf.int64, name=None)}, TensorSpec(shape=(None, 20), dtype=tf.int64, name=None))>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yx12crftrkjQ",
    "outputId": "876ea7b8-614a-409d-d927-c02188d01c60"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "english [[1439   13 1143 ...    0    0    0]\n",
      " [   3  214    7 ...    0    0    0]\n",
      " [  87   51    5 ...    0    0    0]\n",
      " ...\n",
      " [  15    5   17 ...    0    0    0]\n",
      " [   6  319  493 ...    0    0    0]\n",
      " [   6 1186    7 ...    0    0    0]],\n",
      "\n",
      "\n",
      " inputs['english'].shape: (64, 20)\n",
      "spanish [[   2   35  287 ...    0    0    0]\n",
      " [   2  434   18 ...    0    0    0]\n",
      " [   2   83  523 ...    0    0    0]\n",
      " ...\n",
      " [   2   94   18 ...    0    0    0]\n",
      " [   2    8 7995 ...    0    0    0]\n",
      " [   2    8   26 ...    0    0    0]],\n",
      "\n",
      "\n",
      " inputs['spanish'].shape: (64, 20)\n",
      "targets [[  35  287  113 ...    0    0    0]\n",
      " [ 434   18    1 ...    0    0    0]\n",
      " [  83  523   28 ...    0    0    0]\n",
      " ...\n",
      " [  94   18  531 ...    0    0    0]\n",
      " [   8 7995   84 ...    0    0    0]\n",
      " [   8   26 1367 ...    0    0    0]], \n",
      "\n",
      "\n",
      " targets.shape: (64, 20)\n"
     ]
    }
   ],
   "source": [
    "for inputs, targets in train_ds.take(1):\n",
    "    print(f\"english {inputs['english']},\\n\\n\\n inputs['english'].shape: {inputs['english'].shape}\")\n",
    "    print(f\"spanish {inputs['spanish']},\\n\\n\\n inputs['spanish'].shape: {inputs['spanish'].shape}\")\n",
    "    print(f\"targets {targets}, \\n\\n\\n targets.shape: {targets.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x6BfulGQrnwE"
   },
   "source": [
    "## Sequence-to-sequence learning with Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sBXzMh2xol1S"
   },
   "source": [
    "### Positional Embedding\n",
    "This layer combines word/token embeddings with positional embeddings so that the transformer model can understand the order of words in a sentence. Positional Embedding ensures that the transformer knows not only what words are present, but also their order in the sentence. Without this component, the transformer would simply see words as an unordered \"bag of words.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "kfr7tYlIYcio"
   },
   "outputs": [],
   "source": [
    "class PositionalEmbedding(Layer):\n",
    "    def __init__(self, sequence_length, input_dim, output_dim, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        \n",
    "        # Translates ID tokens (numbers) into a vector of dimension output_dim.\n",
    "        self.token_embeddings = Embedding(\n",
    "            input_dim=input_dim, output_dim=output_dim, mask_zero=True  # aktifkan masking otomatis!\n",
    "        )\n",
    "        \n",
    "        #intermediate = self.getPositionEncoding(seq_len=input_dim,d=vocab_size,n=output_dim)\n",
    "        #Positions 0, 1, 2, ..., sequence_length-1 are embedded like regular tokens.\n",
    "        #Difference: The input here is a sequence of positions, not word IDs.\n",
    "        \n",
    "        self.position_embeddings = Embedding(\n",
    "            input_dim=sequence_length, output_dim=output_dim\n",
    "        )\n",
    "        self.sequence_length = sequence_length\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # Use fixed length of self.sequence_length\n",
    "        positions = tf.range(start=0, limit=tf.shape(inputs)[-1], delta=1)\n",
    "        positions = self.position_embeddings(positions) # (1, sequence_length)\n",
    "        x = self.token_embeddings(inputs)\n",
    "        return x + positions\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            \"sequence_length\": self.sequence_length,\n",
    "            \"input_dim\": self.input_dim,\n",
    "            \"output_dim\": self.output_dim,\n",
    "        })\n",
    "        return config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hIiAG8fWoxSS"
   },
   "source": [
    "### Transformer Encoder\n",
    "The `TransformerEncoder` is the encoder block of the transformer architecture, which captures the relationships between words in a sentence using self-attention and a feed-forward network.\n",
    "\n",
    "`TransformerEncoder = Self-Attention + Feed-Forward + Residual + Normalization`\\\n",
    "Its function is to build a contextual representation of words → each word does not stand alone, but understands its relationship to other words in the sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "hK4vdx9cX7Uj"
   },
   "outputs": [],
   "source": [
    "class TransformerEncoder(layers.Layer):\n",
    "    def __init__(self, embed_dim, dense_dim, num_heads):\n",
    "        super().__init__()\n",
    "        self.attention = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
    "        self.dense_proj = keras.Sequential([\n",
    "            layers.Dense(dense_dim, activation=\"relu\"),\n",
    "            layers.Dense(embed_dim),\n",
    "        ])\n",
    "        self.layernorm_1 = layers.LayerNormalization()\n",
    "        self.layernorm_2 = layers.LayerNormalization()\n",
    "\n",
    "    def call(self, inputs, mask=None):\n",
    "        attention_output = self.attention(inputs, inputs, attention_mask=None)\n",
    "        proj_input = self.layernorm_1(inputs + attention_output)\n",
    "        proj_output = self.dense_proj(proj_input)\n",
    "        return self.layernorm_2(proj_input + proj_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S_MkR9QyozOk"
   },
   "source": [
    "### Transformer Decoder\n",
    "The TransformerDecoder is responsible for generating an output sequence based on the representation provided by the encoder, while ensuring that the generation process is autoregressive (only looking at previous tokens).\n",
    "\n",
    "In short, the decoder combines two aspects:\n",
    "* Autoregressive generation (only looking at the past through masked self-attention).\n",
    "* The global context of the input (through cross-attention to the encoder)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "hpLNJHi-X9pC"
   },
   "outputs": [],
   "source": [
    "class TransformerDecoder(layers.Layer):\n",
    "    # A constructor containing multihead plus masked self attention\n",
    "    def __init__(self, embed_dim, dense_dim, num_heads):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Masked self-attention: only looks at the previous token, so as not to \"peek into the future\".\n",
    "        self.attention_1 = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
    "        \n",
    "        # Cross-attention: connects the output of the encoder to the decoder (input from the source language).\n",
    "        self.attention_2 = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
    "        \n",
    "        # Feedforward network: 2 Dense layers as non-linear processing.\n",
    "        self.dense_proj = keras.Sequential([\n",
    "            layers.Dense(dense_dim, activation=\"relu\"),\n",
    "            layers.Dense(embed_dim),\n",
    "        ])\n",
    "        \n",
    "        # Normalization at each stage (after residual connection).\n",
    "        self.layernorm_1 = layers.LayerNormalization()\n",
    "        self.layernorm_2 = layers.LayerNormalization()\n",
    "        self.layernorm_3 = layers.LayerNormalization()\n",
    "\n",
    "    # Create a lower triangle mask (causal mask) of size [batch, seq_len, seq_len]\n",
    "    # Prevents the i-th position from looking at the j-th token > i.\n",
    "    # It is used so that when training the decoder model it does not know the next token (future blindness).\n",
    "    def get_causal_attention_mask(self, inputs):\n",
    "        i = tf.range(tf.shape(inputs)[1])[:, tf.newaxis]\n",
    "        j = tf.range(tf.shape(inputs)[1])\n",
    "        mask = tf.cast(i >= j, dtype=\"int32\")\n",
    "        return tf.reshape(mask, (1, tf.shape(inputs)[1], tf.shape(inputs)[1]))\n",
    "\n",
    "    def call(self, inputs, encoder_outputs, mask=None):\n",
    "        \n",
    "        # Create a mask for self-attention, so as not to “peek ahead”.\n",
    "        causal_mask = self.get_causal_attention_mask(inputs)\n",
    "        \n",
    "        # Masked Self-Attention\n",
    "        # Focus only on the previous or current token. Add residual + layernorm\n",
    "        attention_output_1 = self.attention_1(inputs, inputs, attention_mask=causal_mask)\n",
    "        attention_output_1 = self.layernorm_1(inputs + attention_output_1)\n",
    "        \n",
    "        # Cross Attention (Decoder attends to Encoder)\n",
    "        # Connecting the target representation with the representation generated by the encoder (e.g. from an English sentence).\n",
    "        attention_output_2 = self.attention_2(attention_output_1, encoder_outputs, encoder_outputs)\n",
    "        attention_output_2 = self.layernorm_2(attention_output_1 + attention_output_2)\n",
    "        \n",
    "        # FFN strengthens the token representation. Then, residual connection and layer normalization are performed.\n",
    "        proj_output = self.dense_proj(attention_output_2)\n",
    "        return self.layernorm_3(attention_output_2 + proj_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XZ29cZR3o3Ws"
   },
   "source": [
    "### Build a Transformer Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Determines the size of the representation vector for each token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim = 256"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Determines the size of the hidden layer in the FFN block in the encoder and decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_dim = 2048"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Determines the size of the number of parallel attention heads in the attention layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_heads = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defines the input for the source language (English) in the form of a sequence of ID tokens, with dynamic length (None)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"english\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### English token representation that takes into account word order/position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:232: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(encoder_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Full context representation for the entire input sentence (English)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_outputs = TransformerEncoder(embed_dim, dense_dim, num_heads)(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Input is an ID token for the target language (Spanish), used during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "6cXSxHirX_lU"
   },
   "outputs": [],
   "source": [
    "decoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"spanish\")\n",
    "x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(decoder_inputs)\n",
    "x = TransformerDecoder(embed_dim, dense_dim, num_heads)(x, encoder_outputs)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "decoder_outputs = layers.Dense(vocab_size, activation=\"softmax\")(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = keras.Model([encoder_inputs, decoder_inputs], decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ english             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ spanish             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ positional_embeddi… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">3,845,120</span> │ english[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">PositionalEmbeddi…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ positional_embeddi… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">3,845,120</span> │ spanish[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">PositionalEmbeddi…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ transformer_encoder │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">3,155,456</span> │ positional_embed… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncode…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ transformer_decoder │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">5,259,520</span> │ positional_embed… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerDecode…</span> │                   │            │ transformer_enco… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ transformer_deco… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │  <span style=\"color: #00af00; text-decoration-color: #00af00\">3,855,000</span> │ dropout_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">15000</span>)            │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ english             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ spanish             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ positional_embeddi… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m) │  \u001b[38;5;34m3,845,120\u001b[0m │ english[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "│ (\u001b[38;5;33mPositionalEmbeddi…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ positional_embeddi… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m) │  \u001b[38;5;34m3,845,120\u001b[0m │ spanish[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "│ (\u001b[38;5;33mPositionalEmbeddi…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ transformer_encoder │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m) │  \u001b[38;5;34m3,155,456\u001b[0m │ positional_embed… │\n",
       "│ (\u001b[38;5;33mTransformerEncode…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ transformer_decoder │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m) │  \u001b[38;5;34m5,259,520\u001b[0m │ positional_embed… │\n",
       "│ (\u001b[38;5;33mTransformerDecode…\u001b[0m │                   │            │ transformer_enco… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ transformer_deco… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m,      │  \u001b[38;5;34m3,855,000\u001b[0m │ dropout_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│                     │ \u001b[38;5;34m15000\u001b[0m)            │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">19,960,216</span> (76.14 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m19,960,216\u001b[0m (76.14 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">19,960,216</span> (76.14 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m19,960,216\u001b[0m (76.14 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "transformer.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Interpretation\n",
    "1. Input Layer\n",
    "    * english (InputLayer) → (None, None)\\\n",
    "      Input English text sequence (sequence length is flexible).\n",
    "    * spanish (InputLayer) → (None, None)\\\n",
    "      Input Spanish text sequence (target sequence).\n",
    "2. Positional Embedding\n",
    "    * positional_embedding (english) → (None, None, 256) | 3,845,120 parameters\n",
    "    * positional_embedding (spanish) → (None, None, 256) | 3,845,120 parameters\n",
    "    * Each token (both input and target) is converted into a 256-dimensional embedding vector, then positional information is added so the model knows the word order.\n",
    "    * Parameter = vocab_size * embedding_dim (here approximately 15k * 256 = 3.8 million).\n",
    "3. Transformer Encoder\n",
    "    * transformer_encoder → (None, None, 256) | 3,155,456 parameters\n",
    "    * Accepts an English embedding input and processes it through:\n",
    "      - Multi-Head Self-Attention\n",
    "      - Feedforward Network (dense projection)\n",
    "      - Residual + Normalization\n",
    "    * The output is a contextual representation of English.\n",
    "4. Transformer Decoder\n",
    "    * transformer_decoder → (None, None, 256) | 5,259,520 parameters\n",
    "    * Accepts:\n",
    "        - Target sequence embedding (Spanish)\n",
    "        - Encoder representation (English)\n",
    "    * The process includes:\n",
    "        - Masked Self-Attention (only allows the previous token to be seen in the output).\n",
    "        - Cross-Attention (connects the target to the encoder representation).\n",
    "        - Feedforward Network.\n",
    "    * The output is a representation of the target token that already “knows the context of the previous input + output.”\n",
    "5. Dropout\n",
    "    * dropout_3 → (None, None, 256)\\\n",
    "      Regularization layer to prevent overfitting.\n",
    "6. Dense (Output Layer)\n",
    "    * dense_4 (Dense) → (None, None, 15000) | 3,855,000 parameters\n",
    "    * A linear layer that maps the 256-dimensional model to the target vocabulary size (15k).\n",
    "    * Each target token is projected onto a word probability distribution via softmax.\n",
    "7. Total Parameters\n",
    "    * Total parameters = ~20 million (76 MB)\n",
    "    * All trainable (no frozen parameters).\n",
    "8. Core Architecture\n",
    "    * This model is a seq2seq Transformer for machine translation (English → Spanish) with:\n",
    "        - 256-dimensional embedding\n",
    "        - Encoder + Decoder stack\n",
    "        - Target vocabulary size 15k\n",
    "        - Total 20 million parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 790
    },
    "id": "0gXDlsdHSJsA",
    "outputId": "954dd941-caea-4f35-ece5-53e84775238b"
   },
   "outputs": [],
   "source": [
    "#from tensorflow.keras.utils import plot_model\n",
    "#from IPython.display import Image\n",
    "\n",
    "#plot_model(transformer, to_file='transformer.png', show_shapes=True)\n",
    "#Image(filename='transformer.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UWZOsUxrx-9b"
   },
   "source": [
    "The lighter setting (faster training) will be named vanguard and the initial setting will be named transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a Vanguard Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determine the initial configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim = 128\n",
    "dense_dim = 512\n",
    "num_heads = 4\n",
    "sequence_length = 20\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defines the input for the source language (English) in the form of a sequence of ID tokens, with dynamic length (None)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"english\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### English token representation that takes into account word order/position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(encoder_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full context representation for the entire input sentence (English)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_outputs = TransformerEncoder(embed_dim, dense_dim, num_heads)(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input is an ID token for the target language (Spanish), used during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "m5_AHHrbyFhh"
   },
   "outputs": [],
   "source": [
    "decoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"spanish\")\n",
    "x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(decoder_inputs)\n",
    "x = TransformerDecoder(embed_dim, dense_dim, num_heads)(x, encoder_outputs)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "decoder_outputs = layers.Dense(vocab_size, activation=\"softmax\")(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "vanguard = keras.Model([encoder_inputs, decoder_inputs], decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_5\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_5\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ english             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ spanish             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ positional_embeddi… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,922,560</span> │ english[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">PositionalEmbeddi…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ positional_embeddi… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,922,560</span> │ spanish[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">PositionalEmbeddi…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ transformer_encode… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) │    <span style=\"color: #00af00; text-decoration-color: #00af00\">396,032</span> │ positional_embed… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncode…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ transformer_decode… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) │    <span style=\"color: #00af00; text-decoration-color: #00af00\">660,096</span> │ positional_embed… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerDecode…</span> │                   │            │ transformer_enco… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ transformer_deco… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,935,000</span> │ dropout_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">15000</span>)            │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ english             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ spanish             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ positional_embeddi… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m) │  \u001b[38;5;34m1,922,560\u001b[0m │ english[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "│ (\u001b[38;5;33mPositionalEmbeddi…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ positional_embeddi… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m) │  \u001b[38;5;34m1,922,560\u001b[0m │ spanish[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "│ (\u001b[38;5;33mPositionalEmbeddi…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ transformer_encode… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m) │    \u001b[38;5;34m396,032\u001b[0m │ positional_embed… │\n",
       "│ (\u001b[38;5;33mTransformerEncode…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ transformer_decode… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m) │    \u001b[38;5;34m660,096\u001b[0m │ positional_embed… │\n",
       "│ (\u001b[38;5;33mTransformerDecode…\u001b[0m │                   │            │ transformer_enco… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_7 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ transformer_deco… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m,      │  \u001b[38;5;34m1,935,000\u001b[0m │ dropout_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│                     │ \u001b[38;5;34m15000\u001b[0m)            │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,836,248</span> (26.08 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m6,836,248\u001b[0m (26.08 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,836,248</span> (26.08 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m6,836,248\u001b[0m (26.08 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vanguard.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Interpretation\n",
    "1. Input Layer\n",
    "    * english (InputLayer): accepts input in the form of English sequence tokens.\n",
    "    * spanish (InputLayer): accepts input in the form of Spanish sequence tokens.\n",
    "    * Both are of the form (None, None) → meaning the sequence length is flexible, and the batch size is also flexible.\n",
    "2. Positional Embedding\n",
    "    * english → positional_embedding:\n",
    "        - Token embedding + positional embedding, resulting in a 128-dimensional representation.\n",
    "        - Number of parameters: 1,922,560\n",
    "        - → This is derived from the vocabulary size (input_dim) × output_dim (128).\n",
    "    * spanish → positional_embedding_1:\n",
    "        - Same as above, for Spanish.\n",
    "        - The parameters are also 1,922,560.\n",
    "        - These two embeddings ensure that both English and Spanish tokens have a vector representation + positional information in the sequence.\n",
    "3. Transformer Encoder\n",
    "    * Input: English embedding.\n",
    "    * Process: self-attention + feedforward network + residual + norm layer.\n",
    "    * Output: 128-dimensional English contextual representation.\n",
    "    * Parameters: 396,032 (quite light because embed_dim is only 128 and the number of heads is limited).\n",
    "4. Transformer Decoder\n",
    "    * Main input: Spanish embedding.\n",
    "    * Additional input: the output from the encoder (English).\n",
    "    * Process: masked self-attention for the decoder, cross-attention to the encoder output, then feedforward network.\n",
    "    * Output: Spanish representation connected to the English context.\n",
    "    * Parameters: 660,096 (larger than the encoder, due to additional cross-attention).\n",
    "5. Dropout\n",
    "    * dropout_7: maintains generalization, prevents overfitting.\n",
    "6. Dense Output Layer\n",
    "    * dense_9 (Dense, 15,000 units):\n",
    "    * Output is a probability distribution over 15,000 words (assuming target vocabulary size = 15k).\n",
    "    * Parameters: 1,935,000 (128 × 15,000 + bias).\n",
    "7. Total Parameters\n",
    "    * 6,836,248 (~6.8M parameters)\n",
    "    * Very lightweight compared to standard Transformer models (for example, the original Transformer can have hundreds of millions of parameters).\n",
    "    * It's reasonable to call it \"vanguard\" because it's compact and easy to train with limited resources.\n",
    "8. Concise Interpretation\n",
    "    * This vanguard model is a seq2seq Transformer for English → Spanish translation.\n",
    "    * The encoder understands English sentences.\n",
    "    * The decoder generates Spanish sentences based on the encoder's output.\n",
    "    * The small embedding size (128) and limited vocabulary (15k) make this model lightweight, with only 6.8 million parameters.\n",
    "    * This makes the model suitable for academic experiments, portfolios, or training on laptops without large GPUs, while still maintaining the typical Transformer (encoder–decoder) architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 790
    },
    "id": "guado_pXSMAc",
    "outputId": "87b973d1-90ea-4e4f-8d90-f40b6106c33a"
   },
   "outputs": [],
   "source": [
    "#from tensorflow.keras.utils import plot_model\n",
    "#plot_model(vanguard, to_file='vanguard.png', show_shapes=True)\n",
    "#from IPython.display import Image\n",
    "#Image(\"vanguard.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tx45csyNo6sc"
   },
   "source": [
    "## Compile and Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transformer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DlV-JNHuYBWM",
    "outputId": "c31b233a-23b1-4ff1-a280-c6ab32350dcd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.7119 - loss: 2.2096   \n",
      "Epoch 1: saving model to language_translation_checkpoint.weights.h5\n",
      "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1919s\u001b[0m 1s/step - accuracy: 0.7410 - loss: 1.7738 - val_accuracy: 0.8032 - val_loss: 1.2309\n",
      "Epoch 2/5\n",
      "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8128 - loss: 1.1956   \n",
      "Epoch 2: saving model to language_translation_checkpoint.weights.h5\n",
      "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1915s\u001b[0m 1s/step - accuracy: 0.8258 - loss: 1.1047 - val_accuracy: 0.8527 - val_loss: 0.8826\n",
      "Epoch 3/5\n",
      "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8513 - loss: 0.9121   \n",
      "Epoch 3: saving model to language_translation_checkpoint.weights.h5\n",
      "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1909s\u001b[0m 1s/step - accuracy: 0.8558 - loss: 0.8783 - val_accuracy: 0.8664 - val_loss: 0.7800\n",
      "Epoch 4/5\n",
      "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8673 - loss: 0.7910   \n",
      "Epoch 4: saving model to language_translation_checkpoint.weights.h5\n",
      "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1915s\u001b[0m 1s/step - accuracy: 0.8700 - loss: 0.7721 - val_accuracy: 0.8732 - val_loss: 0.7397\n",
      "Epoch 5/5\n",
      "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8771 - loss: 0.7197   \n",
      "Epoch 5: saving model to language_translation_checkpoint.weights.h5\n",
      "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1919s\u001b[0m 1s/step - accuracy: 0.8791 - loss: 0.7063 - val_accuracy: 0.8776 - val_loss: 0.7145\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2535baf4830>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer.compile(\n",
    "    optimizer=\"rmsprop\",\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(\n",
    "    filepath=\"language_translation_checkpoint.weights.h5\",\n",
    "    save_weights_only=True,\n",
    "    verbose=1,\n",
    "    monitor=\"val_accuracy\"\n",
    ")\n",
    "\n",
    "transformer.fit(train_ds, epochs=5, validation_data=val_ds, callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f8mHnyfmyJaR"
   },
   "source": [
    "#### Vanguard model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oMsWkXCOyK2o",
    "outputId": "2ef11882-7ebd-4b17-f626-5a67591c0968"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 442ms/step - accuracy: 0.7038 - loss: 2.5846  \n",
      "Epoch 1: saving model to language_translation_checkpoint.weights.h5\n",
      "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m636s\u001b[0m 475ms/step - accuracy: 0.7359 - loss: 1.9178 - val_accuracy: 0.7923 - val_loss: 1.3261\n",
      "Epoch 2/5\n",
      "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 441ms/step - accuracy: 0.7992 - loss: 1.3207  \n",
      "Epoch 2: saving model to language_translation_checkpoint.weights.h5\n",
      "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m615s\u001b[0m 472ms/step - accuracy: 0.8105 - loss: 1.2402 - val_accuracy: 0.8381 - val_loss: 1.0146\n",
      "Epoch 3/5\n",
      "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 442ms/step - accuracy: 0.8354 - loss: 1.0641  \n",
      "Epoch 3: saving model to language_translation_checkpoint.weights.h5\n",
      "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m616s\u001b[0m 473ms/step - accuracy: 0.8403 - loss: 1.0310 - val_accuracy: 0.8561 - val_loss: 0.8999\n",
      "Epoch 4/5\n",
      "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 441ms/step - accuracy: 0.8521 - loss: 0.9484  \n",
      "Epoch 4: saving model to language_translation_checkpoint.weights.h5\n",
      "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m616s\u001b[0m 473ms/step - accuracy: 0.8546 - loss: 0.9320 - val_accuracy: 0.8611 - val_loss: 0.8575\n",
      "Epoch 5/5\n",
      "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 441ms/step - accuracy: 0.8615 - loss: 0.8867  \n",
      "Epoch 5: saving model to language_translation_checkpoint.weights.h5\n",
      "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m616s\u001b[0m 473ms/step - accuracy: 0.8631 - loss: 0.8764 - val_accuracy: 0.8666 - val_loss: 0.8336\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x25329175e50>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vanguard.compile(\n",
    "    optimizer=\"rmsprop\",\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(\n",
    "    filepath=\"language_translation_checkpoint.weights.h5\",\n",
    "    save_weights_only=True,\n",
    "    verbose=1,\n",
    "    monitor=\"val_accuracy\"\n",
    ")\n",
    "\n",
    "vanguard.fit(train_ds, epochs=5, validation_data=val_ds, callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training Performance Comparison\n",
    "1. Initial Training (Epoch 1)\n",
    "    * Transformer: train acc 74%, val acc 80% (quite high from the start → fast adaptation).\n",
    "    * Vanguard: train acc 73%, val acc 79% (slightly lower, but still good).\n",
    "2. Progress Over 5 Epochs\n",
    "    * Transformer: consistently increased to a val acc of 87.7% with a val loss of 0.71.\n",
    "    * Vanguard: also steadily increased but slightly lower, with a val acc of 86.6% with a val loss of 0.83.\n",
    "    * Transformer has a +1% advantage in validation accuracy and lower val loss → better generalization.\n",
    "3. Training Speed\n",
    "    * Transformer: 1900 seconds/epoch (32 minutes).\n",
    "    * Vanguard: 616 seconds/epoch (10 minutes).\n",
    "    * Vanguard is 3x faster, but with the trade-off of slightly lower accuracy.\n",
    "#### Interpretation\n",
    "* Transformer is indeed heavier (self-attention complexity, deeper embedding, etc.), but produces more accurate and stable results.\n",
    "* Vanguard is lighter and faster to train, suitable for resource-constrained environments, but there is a trade-off in final accuracy.\n",
    "* The accuracy gap is not too large (87.7% vs. 86.6%), so the choice depends on the context of use:\n",
    "    - If absolute accuracy is critical (e.g., production-level machine translation) → choose Transformer.\n",
    "    - If time and resources are constraints (e.g., for prototyping, edge devices, or rapid iteration) → Vanguard is more efficient.\n",
    "* These results demonstrate Transformer's superiority not only as a robust model for natural language, but also as a very solid baseline.\n",
    "* Vanguard, as a lighter variant, can be positioned as an alternative trade-off between accuracy and speed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T2-E06uKo9ff"
   },
   "source": [
    "## Evaluate BLEU Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transformer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "trM8O_CIZovW",
    "outputId": "6e16f33a-e2a1-46da-e71a-4c67e5a441e3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: Take it easy!\n",
      "Prediction: toma fácil end                 \n",
      "Target: [['¡Relajate!']]\n",
      "BLEU: 0.0000\n",
      "\n",
      "Input: Will he succeed or fail?\n",
      "Prediction: va a triunfar o no end              \n",
      "Target: [['¿Él', 'triunfará', 'o', 'fracasará?']]\n",
      "BLEU: 0.0000\n",
      "\n",
      "Input: I resign.\n",
      "Prediction: yo [UNK] end                 \n",
      "Target: [['Dimito.']]\n",
      "BLEU: 0.0000\n",
      "\n",
      "Input: He had more than enough money.\n",
      "Prediction: Él tuvo más de dinero suficiente dinero end            \n",
      "Target: [['Él', 'tenía', 'más', 'que', 'suficiente', 'dinero.']]\n",
      "BLEU: 0.0000\n",
      "\n",
      "Input: I was trying not to look.\n",
      "Prediction: no estaba intentando mirar end               \n",
      "Target: [['Trataba', 'de', 'no', 'mirar.']]\n",
      "BLEU: 0.0000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Assume test_pairs = [(eng, spa), ...]\n",
    "def decode_sequence(input_sentence):\n",
    "    tokenized_input = source_vectorization([input_sentence])\n",
    "    decoded_sentence = \"[start]\"\n",
    "    for i in range(sequence_length):\n",
    "        tokenized_target = target_vectorization([decoded_sentence])[:, :-1]\n",
    "        predictions = transformer.predict({\"english\": tokenized_input, \"spanish\": tokenized_target}, verbose=0)\n",
    "        sampled_token_index = np.argmax(predictions[0, i, :])\n",
    "        sampled_token = target_vectorization.get_vocabulary()[sampled_token_index]\n",
    "        if sampled_token == \"[end]\":\n",
    "            break\n",
    "        decoded_sentence += \" \" + sampled_token\n",
    "    return decoded_sentence.replace(\"[start] \", \"\")\n",
    "\n",
    "# BLEU Evaluation\n",
    "for _ in range(5):\n",
    "    input_text, target_text = random.choice(test_pairs)\n",
    "    prediction = decode_sequence(input_text)\n",
    "    reference = [target_text.replace(\"[start] \", \"\").replace(\" [end]\", \"\").split()]\n",
    "    candidate = prediction.split()\n",
    "    bleu_score = sentence_bleu(reference, candidate)\n",
    "    print(f\"Input: {input_text}\\nPrediction: {prediction}\\nTarget: {reference}\\nBLEU: {bleu_score:.4f}\\n\")\n",
    "\n",
    "### Save Final Model\n",
    "transformer.save(\"transformer_translation_model.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5lSAj01_yNE6"
   },
   "source": [
    "#### Vanguard model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KBqC-zkMyOI6",
    "outputId": "90c8233e-8c01-4dc6-d65f-97d5f9289b61"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: I hope we meet again someday soon.\n",
      "Prediction: espero que nos [UNK] otra vez end             \n",
      "Target: [['Espero', 'que', 'algún', 'día', 'pronto', 'nos', 'volvamos', 'a', 'ver.']]\n",
      "BLEU: 0.0000\n",
      "\n",
      "Input: Please put a lot of cream in my coffee.\n",
      "Prediction: por favor [UNK] mucho en el café end            \n",
      "Target: [['Ponele', 'mucha', 'crema', 'a', 'mi', 'café,', 'por', 'favor.']]\n",
      "BLEU: 0.0000\n",
      "\n",
      "Input: Come on, try again.\n",
      "Prediction: ven a intentar end                \n",
      "Target: [['Vamos,', 'inténtalo', 'otra', 'vez.']]\n",
      "BLEU: 0.0000\n",
      "\n",
      "Input: All human beings are mortal.\n",
      "Prediction: todas las [UNK] son [UNK] end              \n",
      "Target: [['Todos', 'los', 'humanos', 'son', 'mortales.']]\n",
      "BLEU: 0.0000\n",
      "\n",
      "Input: Can I have some of these?\n",
      "Prediction: puedo tener algo de estas end              \n",
      "Target: [['¿Puede', 'darme', 'algunos', 'de', 'éstos?']]\n",
      "BLEU: 0.0000\n",
      "\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[Errno 28] No space left on device",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[53], line 25\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInput: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_text\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mPrediction: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprediction\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mTarget: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mreference\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mBLEU: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbleu_score\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m### Save Final Model\u001b[39;00m\n\u001b[1;32m---> 25\u001b[0m vanguard\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvanguard_translation_model.keras\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\zipfile\\__init__.py:1949\u001b[0m, in \u001b[0;36mZipFile.writestr\u001b[1;34m(self, zinfo_or_arcname, data, compress_type, compresslevel)\u001b[0m\n\u001b[0;32m   1947\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   1948\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mopen(zinfo, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m dest:\n\u001b[1;32m-> 1949\u001b[0m         dest\u001b[38;5;241m.\u001b[39mwrite(data)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\zipfile\\__init__.py:1252\u001b[0m, in \u001b[0;36m_ZipWriteFile.write\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m   1250\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compressor\u001b[38;5;241m.\u001b[39mcompress(data)\n\u001b[0;32m   1251\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compress_size \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(data)\n\u001b[1;32m-> 1252\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fileobj\u001b[38;5;241m.\u001b[39mwrite(data)\n\u001b[0;32m   1253\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m nbytes\n",
      "\u001b[1;31mOSError\u001b[0m: [Errno 28] No space left on device"
     ]
    }
   ],
   "source": [
    "# Assume test_pairs = [(eng, spa), ...]\n",
    "def decode_sequence(input_sentence):\n",
    "    tokenized_input = source_vectorization([input_sentence])\n",
    "    decoded_sentence = \"[start]\"\n",
    "    for i in range(sequence_length):\n",
    "        tokenized_target = target_vectorization([decoded_sentence])[:, :-1]\n",
    "        predictions = vanguard.predict({\"english\": tokenized_input, \"spanish\": tokenized_target}, verbose=0)\n",
    "        sampled_token_index = np.argmax(predictions[0, i, :])\n",
    "        sampled_token = target_vectorization.get_vocabulary()[sampled_token_index]\n",
    "        if sampled_token == \"[end]\":\n",
    "            break\n",
    "        decoded_sentence += \" \" + sampled_token\n",
    "    return decoded_sentence.replace(\"[start] \", \"\")\n",
    "\n",
    "# BLEU Evaluation\n",
    "for _ in range(5):\n",
    "    input_text, target_text = random.choice(test_pairs)\n",
    "    prediction = decode_sequence(input_text)\n",
    "    reference = [target_text.replace(\"[start] \", \"\").replace(\" [end]\", \"\").split()]\n",
    "    candidate = prediction.split()\n",
    "    bleu_score = sentence_bleu(reference, candidate)\n",
    "    print(f\"Input: {input_text}\\nPrediction: {prediction}\\nTarget: {reference}\\nBLEU: {bleu_score:.4f}\\n\")\n",
    "\n",
    "### Save Final Model\n",
    "vanguard.save(\"vanguard_translation_model.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_ZwysUrQpBA0"
   },
   "source": [
    "### Saving model architecture in json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "SYqvQ-BXm8wd"
   },
   "outputs": [],
   "source": [
    "model_json = transformer.to_json()\n",
    "with open(\"translator.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cV78i6xYnCyg"
   },
   "source": [
    "**Translate new sentences with Transformer model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "3atnDjYMnCgy"
   },
   "outputs": [],
   "source": [
    "spa_vocab = target_vectorization.get_vocabulary()\n",
    "spa_index_lookup = dict(zip(range(len(spa_vocab)), spa_vocab))\n",
    "max_decoded_sentence_length = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KIsz7TWOyPOS"
   },
   "source": [
    "**Translate new sentences with vanguard model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "eaeM28gVyQkC"
   },
   "outputs": [],
   "source": [
    "spa_vocab = target_vectorization.get_vocabulary()\n",
    "spa_index_lookup = dict(zip(range(len(spa_vocab)), spa_vocab))\n",
    "max_decoded_sentence_length = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W5h5iutFnGO7"
   },
   "source": [
    "### Output Testing and Decoding the output sequence with transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "nOcRWT4em95P"
   },
   "outputs": [],
   "source": [
    "def transformer_decode_sequence(input_sentence):\n",
    "    tokenized_input_sentence = source_vectorization([input_sentence])\n",
    "    transformer_decoded_sentence = \"[start]\"\n",
    "    for i in range(max_decoded_sentence_length):\n",
    "        tokenized_target_sentence = target_vectorization(\n",
    "            [transformer_decoded_sentence])[:, :-1]\n",
    "        predictions = transformer(\n",
    "            [tokenized_input_sentence, tokenized_target_sentence])\n",
    "        sampled_token_index = np.argmax(predictions[0, i, :])\n",
    "        sampled_token = spa_index_lookup[sampled_token_index]\n",
    "        transformer_decoded_sentence += \" \" + sampled_token\n",
    "        if sampled_token == \"[end]\":\n",
    "            break\n",
    "    return transformer_decoded_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output Testing and Decoding the output sequence with vanguard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vanguard_decode_sequence(input_sentence):\n",
    "    tokenized_input_sentence = source_vectorization([input_sentence])\n",
    "    vanguard_decoded_sentence = \"[start]\"\n",
    "    for i in range(max_decoded_sentence_length):\n",
    "        tokenized_target_sentence = target_vectorization(\n",
    "            [vanguard_decoded_sentence])[:, :-1]\n",
    "        predictions = vanguard(\n",
    "            [tokenized_input_sentence, tokenized_target_sentence])\n",
    "        sampled_token_index = np.argmax(predictions[0, i, :])\n",
    "        sampled_token = spa_index_lookup[sampled_token_index]\n",
    "        vanguard_decoded_sentence += \" \" + sampled_token\n",
    "        if sampled_token == \"[end]\":\n",
    "            break\n",
    "    return vanguard_decoded_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CPBhqPZhnLBK"
   },
   "source": [
    "### Transformer translating output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "r1SlMTGunHxH",
    "outputId": "4335720d-7387-4271-85ec-c353320092e2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "Does prison reform criminals?\n",
      "[start] [UNK] la cárcel end                \n",
      "-\n",
      "This juice would be even better with two ice cubes.\n",
      "[start] este jugo sería mejor que dos con dos hielo end          \n",
      "-\n",
      "Show me your passport, please.\n",
      "[start] muéstrame su pasaporte por favor end              \n",
      "-\n",
      "You have three seconds to make your choice.\n",
      "[start] tienes tres semanas end                \n",
      "-\n",
      "What he says is true.\n",
      "[start] lo que dice es cierto end              \n"
     ]
    }
   ],
   "source": [
    "test_eng_texts = [pair[0] for pair in test_pairs]\n",
    "for _ in range(5):\n",
    "    input_sentence = random.choice(test_eng_texts)\n",
    "    print(\"-\")\n",
    "    print(input_sentence)\n",
    "    print(transformer_decode_sequence(input_sentence))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ATLqYk6VySob"
   },
   "source": [
    "### Vanguard translating output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jLyavKBmyTh1",
    "outputId": "30ce113b-c712-4723-ace4-166bab0abaec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "I can't decide which car to buy.\n",
      "[start] no puedo decidir qué auto end              \n",
      "-\n",
      "You're quite smart.\n",
      "[start] eres bastante inteligente end                \n",
      "-\n",
      "Tom is seeking a job.\n",
      "[start] tom está buscando trabajo end               \n",
      "-\n",
      "She was heard to criticize the manager.\n",
      "[start] ella estaba oído [UNK] a el [UNK] end            \n",
      "-\n",
      "Tom is extremely busy today.\n",
      "[start] tom está muy ocupado hoy end              \n"
     ]
    }
   ],
   "source": [
    "test_eng_texts = [pair[0] for pair in test_pairs]\n",
    "for _ in range(5):\n",
    "    input_sentence = random.choice(test_eng_texts)\n",
    "    print(\"-\")\n",
    "    print(input_sentence)\n",
    "    print(vanguard_decode_sequence(input_sentence))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mGgfTe4vnOBY"
   },
   "source": [
    "## Evaluation using the BLEU score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformer BLEU Score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c0ZkyI6KnJBQ",
    "outputId": "e347cd61-cfcf-46db-a86d-ed7adcee8300",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fui a la tienda a comprar algo de comprar un [UNK] y [UNK] end       [start] fui a la tienda a comprar champú y dentífrico. [end]\n",
      "Transformer Score:0.2647058823529412\n",
      "dónde está un hospital end                [start] ¿dónde hay un hospital? [end]\n",
      "Transformer Score:0.34146341463414637\n",
      "es hora de ir a la escuela end             [start] es hora de ir al colegio. [end]\n",
      "Transformer Score:0.2857142857142857\n",
      "no trabajo el domingo end                [start] no trabajo el domingo. [end]\n",
      "Transformer Score:0.3499999999999999\n",
      "queremos información end                  [start] queremos información. [end]\n",
      "Transformer Score:0.3658536585365854\n",
      "tom debería estar bien el lunes end              [start] tom debería estar bien para el lunes. [end]\n",
      "Transformer Score:0.3125\n",
      "te [UNK] este formulario por favor end              [start] ¿podría cumplimentar este formulario, por favor? [end]\n",
      "Transformer Score:0.35294117647058826\n",
      "todos los gato se ama a mi gato end            [start] todo el mundo quiere a mi gato. [end]\n",
      "Transformer Score:0.2608695652173913\n",
      "esa corbata realmente se está realmente end              [start] esa corbata te queda bien. [end]\n",
      "Transformer Score:0.19642857142857142\n",
      "no tengo un lápiz end                [start] no tengo lápiz. [end]\n",
      "Transformer Score:0.3333333333333333\n",
      "es difícil ayudar a ayudar a la ayuda no le quieren tu ayuda end       [start] es difícil ayudar a la gente que no quiere ayuda. [end]\n",
      "Transformer Score:0.24285714285714285\n",
      "Él estaba en el auto end               [start] él durmió en el coche. [end]\n",
      "Transformer Score:0.2631578947368421\n",
      "tom fue [UNK] en un [UNK] en una televisión end           [start] tom estaba acurrucado en un sillón viendo tv. [end]\n",
      "Transformer Score:0.2807017543859649\n",
      "ellos se dice que la vida es tan pequeño end           [start] ellos a menudo dicen que la vida es corta. [end]\n",
      "Transformer Score:0.25925925925925924\n",
      "sé que eres un profesor end               [start] sé que tú eres profesor. [end]\n",
      "Transformer Score:0.2926829268292683\n",
      "[UNK] el plan hasta las diez end              [start] ¿pretendes trabajar hasta las diez? [end]\n",
      "Transformer Score:0.31111111111111106\n",
      "no le digas a nadie más end              [start] pero no le digas a nadie más. [end]\n",
      "Transformer Score:0.3\n",
      "siempre te he [UNK] end                [start] siempre te amé. [end]\n",
      "Transformer Score:0.3157894736842105\n",
      "no pude [UNK] mi [UNK] end               [start] no pude contener mi ira. [end]\n",
      "Transformer Score:0.275\n",
      "está muy enfadado end                 [start] está realmente enfadado. [end]\n",
      "Transformer Score:0.2972972972972973\n",
      "\n",
      "Transformer BLEU score : 5.9/20\n"
     ]
    }
   ],
   "source": [
    "test_eng_texts = [pair[0] for pair in test_pairs]\n",
    "test_spa_texts = [pair[1] for pair in test_pairs]\n",
    "transformer_score = 0\n",
    "transformer_bleu  = 0\n",
    "for i in range(20):\n",
    "    candidate = decode_sequence(test_eng_texts[i])\n",
    "    reference = test_spa_texts[i].lower()\n",
    "    print(candidate,reference)\n",
    "    transformer_score = sentence_bleu(reference, candidate, weights=(1, 0, 0, 0))\n",
    "    transformer_bleu+=transformer_score\n",
    "    print(f\"Transformer Score:{transformer_score}\")\n",
    "print(f\"\\nTransformer BLEU score : {round(transformer_bleu,2)}/20\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "enU_rcSFnPVG",
    "outputId": "e55ec9a9-b7c7-434f-adf8-3433f788f6c8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformer BLEU score : 5.9/20\n"
     ]
    }
   ],
   "source": [
    "print(f\"Transformer BLEU score : {round(transformer_bleu,2)}/20\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ozCcSkc8yVfT"
   },
   "source": [
    "### Vanguard BLEU Score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S6GPXSWKyWkL",
    "outputId": "de1ca1fb-a4fe-429f-cfd7-a5452029412c",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fui a la tienda a comprar algo de comprar un [UNK] y [UNK] end       [start] fui a la tienda a comprar champú y dentífrico. [end]\n",
      "Vanguard Score:0.2647058823529412\n",
      "dónde está un hospital end                [start] ¿dónde hay un hospital? [end]\n",
      "Vanguard Score:0.34146341463414637\n",
      "es hora de ir a la escuela end             [start] es hora de ir al colegio. [end]\n",
      "Vanguard Score:0.2857142857142857\n",
      "no trabajo el domingo end                [start] no trabajo el domingo. [end]\n",
      "Vanguard Score:0.3499999999999999\n",
      "queremos información end                  [start] queremos información. [end]\n",
      "Vanguard Score:0.3658536585365854\n",
      "tom debería estar bien el lunes end              [start] tom debería estar bien para el lunes. [end]\n",
      "Vanguard Score:0.3125\n",
      "te [UNK] este formulario por favor end              [start] ¿podría cumplimentar este formulario, por favor? [end]\n",
      "Vanguard Score:0.35294117647058826\n",
      "todos los gato se ama a mi gato end            [start] todo el mundo quiere a mi gato. [end]\n",
      "Vanguard Score:0.2608695652173913\n",
      "esa corbata realmente se está realmente end              [start] esa corbata te queda bien. [end]\n",
      "Vanguard Score:0.19642857142857142\n",
      "no tengo un lápiz end                [start] no tengo lápiz. [end]\n",
      "Vanguard Score:0.3333333333333333\n",
      "es difícil ayudar a ayudar a la ayuda no le quieren tu ayuda end       [start] es difícil ayudar a la gente que no quiere ayuda. [end]\n",
      "Vanguard Score:0.24285714285714285\n",
      "Él estaba en el auto end               [start] él durmió en el coche. [end]\n",
      "Vanguard Score:0.2631578947368421\n",
      "tom fue [UNK] en un [UNK] en una televisión end           [start] tom estaba acurrucado en un sillón viendo tv. [end]\n",
      "Vanguard Score:0.2807017543859649\n",
      "ellos se dice que la vida es tan pequeño end           [start] ellos a menudo dicen que la vida es corta. [end]\n",
      "Vanguard Score:0.25925925925925924\n",
      "sé que eres un profesor end               [start] sé que tú eres profesor. [end]\n",
      "Vanguard Score:0.2926829268292683\n",
      "[UNK] el plan hasta las diez end              [start] ¿pretendes trabajar hasta las diez? [end]\n",
      "Vanguard Score:0.31111111111111106\n",
      "no le digas a nadie más end              [start] pero no le digas a nadie más. [end]\n",
      "Vanguard Score:0.3\n",
      "siempre te he [UNK] end                [start] siempre te amé. [end]\n",
      "Vanguard Score:0.3157894736842105\n",
      "no pude [UNK] mi [UNK] end               [start] no pude contener mi ira. [end]\n",
      "Vanguard Score:0.275\n",
      "está muy enfadado end                 [start] está realmente enfadado. [end]\n",
      "Vanguard Score:0.2972972972972973\n",
      "Vanguard BLEU score : 5.9/20\n"
     ]
    }
   ],
   "source": [
    "test_eng_texts = [pair[0] for pair in test_pairs]\n",
    "test_spa_texts = [pair[1] for pair in test_pairs]\n",
    "vanguard_score = 0\n",
    "vanguard_bleu  = 0\n",
    "for i in range(20):\n",
    "    candidate = decode_sequence(test_eng_texts[i])\n",
    "    reference = test_spa_texts[i].lower()\n",
    "    print(candidate,reference)\n",
    "    vanguard_score = sentence_bleu(reference, candidate, weights=(1, 0, 0, 0))\n",
    "    vanguard_bleu+=vanguard_score\n",
    "    print(f\"Vanguard Score:{vanguard_score}\")\n",
    "print(f\"Vanguard BLEU score : {round(vanguard_bleu,2)}/20\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bBnMmCeryXq1",
    "outputId": "1f1ed14a-29ba-4bde-f802-643a98b0a589"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vanguard BLEU score : 5.9/20\n"
     ]
    }
   ],
   "source": [
    "print(f\"Vanguard BLEU score : {round(vanguard_bleu,2)}/20\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Translation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Translation with transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O2MEOEv1nXTq",
    "outputId": "754c57cb-5faf-4004-c418-e7da44c326c7",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENGLISH   : She denied having taken part in the scheme.\n",
      "PREDICTED : [start] ella negó haber tomado parte en el plan end           \n",
      "TARGET    : Ella negó haber tomado parte en el plan.\n",
      "BLEU SCORE: 0.5170\n",
      "\n",
      "ENGLISH   : His memory never ceases to astonish me.\n",
      "PREDICTED : [start] su memoria no me [UNK] a [UNK] end            \n",
      "TARGET    : Su memoria me sorprende.\n",
      "BLEU SCORE: 0.0000\n",
      "\n",
      "ENGLISH   : No, I'm not a teacher. I'm only a student.\n",
      "PREDICTED : [start] no soy profesor solo un profesor solo estudiante end           \n",
      "TARGET    : No, no soy maestro. Soy solo un estudiante.\n",
      "BLEU SCORE: 0.0000\n",
      "\n",
      "ENGLISH   : I'll be glad to.\n",
      "PREDICTED : [start] me haré feliz end                \n",
      "TARGET    : Será un placer.\n",
      "BLEU SCORE: 0.0000\n",
      "\n",
      "ENGLISH   : He was wrong in thinking that she'd come to see him.\n",
      "PREDICTED : [start] Él estaba equivocado en ese día en ver que lo ver end        \n",
      "TARGET    : Él se equivocaba al pensar que ella vendría a verle.\n",
      "BLEU SCORE: 0.0000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "\n",
    "# Take a random sample from the validation data\n",
    "for _ in range(5):\n",
    "    input_text, target_text = random.choice(val_pairs)\n",
    "    prediction = transformer_decode_sequence(input_text)\n",
    "\n",
    "    # Reference and prediction formats\n",
    "    reference = [target_text.replace(\"[start] \", \"\").replace(\" [end]\", \"\").split()]\n",
    "    candidate = prediction.split()\n",
    "\n",
    "    transformer_bleu = sentence_bleu(reference, candidate)\n",
    "\n",
    "    print(f\"ENGLISH   : {input_text}\")\n",
    "    print(f\"PREDICTED : {prediction}\")\n",
    "    print(f\"TARGET    : {' '.join(reference[0])}\")\n",
    "    print(f\"BLEU SCORE: {transformer_bleu:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HI80AqunyZO8"
   },
   "source": [
    "#### Translation with vanguard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8Ivp5gnLncjx",
    "outputId": "76ddf643-1efb-44ba-d860-f315c7a2e739",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENGLISH   : Tom knows the man Mary came with.\n",
      "PREDICTED : [start] tom sabe el hombre que vino con mary end           \n",
      "TARGET    : Tom conoce al hombre con el que vino Mary.\n",
      "BLEU SCORE: 0.0000\n",
      "\n",
      "ENGLISH   : Come on in. The water's nice.\n",
      "PREDICTED : [start] ven a el buen agua end              \n",
      "TARGET    : Métete. El agua está rica.\n",
      "BLEU SCORE: 0.0000\n",
      "\n",
      "ENGLISH   : I don't know my father's annual income.\n",
      "PREDICTED : [start] no sé mi padre [UNK] [UNK] end             \n",
      "TARGET    : No conozco los ingresos anuales de mi padre.\n",
      "BLEU SCORE: 0.0000\n",
      "\n",
      "ENGLISH   : Get on your knees.\n",
      "PREDICTED : [start] [UNK] las [UNK] end                \n",
      "TARGET    : Arrodíllate.\n",
      "BLEU SCORE: 0.0000\n",
      "\n",
      "ENGLISH   : I have two dogs, three cats, and six chickens.\n",
      "PREDICTED : [start] tengo dos perros tres gatos y seis [UNK] end           \n",
      "TARGET    : Tengo dos perros, tres gatos y seis gallinas.\n",
      "BLEU SCORE: 0.2778\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "\n",
    "# Take a random sample from the validation data\n",
    "for _ in range(5):\n",
    "    input_text, target_text = random.choice(val_pairs)\n",
    "    prediction = vanguard_decode_sequence(input_text)\n",
    "\n",
    "    # Reference and prediction formats\n",
    "    reference = [target_text.replace(\"[start] \", \"\").replace(\" [end]\", \"\").split()]\n",
    "    candidate = prediction.split()\n",
    "\n",
    "    vanguard_bleu = sentence_bleu(reference, candidate)\n",
    "\n",
    "    print(f\"ENGLISH   : {input_text}\")\n",
    "    print(f\"PREDICTED : {prediction}\")\n",
    "    print(f\"TARGET    : {' '.join(reference[0])}\")\n",
    "    print(f\"BLEU SCORE: {vanguard_bleu:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus Transformer BLEU score: 0.1030\n"
     ]
    }
   ],
   "source": [
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "\n",
    "# Prepare a list for references and candidates\n",
    "references = []\n",
    "candidates = []\n",
    "\n",
    "# Loop over all sentence pairs in the test set\n",
    "for input_text, target_text in test_pairs:\n",
    "    prediction = transformer_decode_sequence(input_text)\n",
    "    \n",
    "    # Clear target (remove start/end tokens)\n",
    "    reference = target_text.replace(\"[start] \", \"\").replace(\" [end]\", \"\").split()\n",
    "    candidate = prediction.split()\n",
    "    \n",
    "    # Add to list for BLEU corpus\n",
    "    references.append([reference])   # penting: list of list\n",
    "    candidates.append(candidate)\n",
    "\n",
    "# Calculate the BLEU corpus\n",
    "transformer_bleu_score = corpus_bleu(references, candidates)\n",
    "print(f\"Corpus Transformer BLEU score: {transformer_bleu_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus Vanguard BLEU score: 0.0867\n"
     ]
    }
   ],
   "source": [
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "\n",
    "# Prepare a list for references and candidates\n",
    "references = []\n",
    "candidates = []\n",
    "\n",
    "# Loop over all sentence pairs in the test set\n",
    "for input_text, target_text in test_pairs:\n",
    "    prediction = vanguard_decode_sequence(input_text)\n",
    "    \n",
    "    # Clear target (remove start/end tokens)\n",
    "    reference = target_text.replace(\"[start] \", \"\").replace(\" [end]\", \"\").split()\n",
    "    candidate = prediction.split()\n",
    "    \n",
    "    # Tambahkan ke list untuk corpus BLEU\n",
    "    references.append([reference])   # penting: list of list\n",
    "    candidates.append(candidate)\n",
    "\n",
    "# Calculate the BLEU corpus\n",
    "vanguard_bleu_score = corpus_bleu(references, candidates)\n",
    "print(f\"Corpus Vanguard BLEU score: {vanguard_bleu_score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FqfXVURfygdb",
    "outputId": "863bc62e-f2f8-4490-bdc3-f5851f46d5af"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 269ms/step - accuracy: 0.8776 - loss: 0.7145 \n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 156ms/step - accuracy: 0.8666 - loss: 0.8336\n",
      "Transformer Evaluation: \n",
      "Validation Accuracy: 0.8776\n",
      "Validation Loss: 0.7145\n",
      "Transformer BLEU score : 0.0/20\n",
      "\n",
      "Vanguard Evaluation: \n",
      "Validation Accuracy: 0.8666\n",
      "Validation Loss: 0.8336\n",
      "Vanguard BLEU score : 0.28/20\n"
     ]
    }
   ],
   "source": [
    "transformer_loss, transformer_acc = transformer.evaluate(val_ds)\n",
    "vanguard_loss, vanguard_acc = vanguard.evaluate(val_ds)\n",
    "print(\"Transformer Evaluation: \")\n",
    "print(f\"Validation Accuracy: {transformer_acc:.4f}\")\n",
    "print(f\"Validation Loss: {transformer_loss:.4f}\")\n",
    "print(f\"Transformer BLEU score : {round(transformer_bleu_score,2)}/20\")\n",
    "print(\"\\nVanguard Evaluation: \")\n",
    "print(f\"Validation Accuracy: {vanguard_acc:.4f}\")\n",
    "print(f\"Validation Loss: {vanguard_loss:.4f}\")\n",
    "print(f\"Vanguard BLEU score : {round(vanguard_bleu,2)}/20\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 274ms/step - accuracy: 0.8776 - loss: 0.7145 \n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 151ms/step - accuracy: 0.8666 - loss: 0.8336\n",
      "Transformer Evaluation: \n",
      "Validation Accuracy: 0.8776\n",
      "Validation Loss: 0.7145\n",
      "Corpus Transformer BLEU score : 0.1030\n",
      "\n",
      "Vanguard Evaluation: \n",
      "Validation Accuracy: 0.8666\n",
      "Validation Loss: 0.8336\n",
      "Corpus Vanguard BLEU score : 0.0867\n"
     ]
    }
   ],
   "source": [
    "transformer_loss, transformer_acc = transformer.evaluate(val_ds)\n",
    "vanguard_loss, vanguard_acc = vanguard.evaluate(val_ds)\n",
    "print(\"Transformer Evaluation: \")\n",
    "print(f\"Validation Accuracy: {transformer_acc:.4f}\")\n",
    "print(f\"Validation Loss: {transformer_loss:.4f}\")\n",
    "print(f\"Corpus Transformer BLEU score : {transformer_bleu_score:.4f}\")\n",
    "print(\"\\nVanguard Evaluation: \")\n",
    "print(f\"Validation Accuracy: {vanguard_acc:.4f}\")\n",
    "print(f\"Validation Loss: {vanguard_loss:.4f}\")\n",
    "print(f\"Corpus Vanguard BLEU score : {vanguard_bleu_score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation\n",
    "1. Accuracy and Loss\n",
    "    * Transformer has a higher accuracy (87.76% vs. 86.66%) and lower loss (0.71 vs. 0.83).\n",
    "    * This means that, token-by-token, Transformer is better at guessing the correct word.\n",
    "2. Corpus BLEU\n",
    "    * Both BLEU scores are still low (around 0.1).\n",
    "    * This is common when the model is not yet fully fluent in constructing sentences that match the ground truth.\n",
    "    * However, Transformer has a higher BLEU score (0.1030 vs. 0.0867), indicating better word order and n-gram fit than Vanguard.\n",
    "3. Inter-metric Fit\n",
    "    * High accuracy + low BLEU → indicates that although many words are predicted correctly, the order or sentence structure is often inappropriate.\n",
    "    * Transformer has a slight advantage in BLEU, meaning that in addition to being more accurate at the word level, it is also slightly better at arranging words into sentences that resemble the target.\n",
    "4. Conclusion\n",
    "    * Transformer consistently outperforms Vanguard across all metrics (accuracy, loss, and corpus BLEU).\n",
    "    * A low BLEU score (around 0.1) indicates the model is still far from natural sentence structure, even though token accuracy is relatively high.\n",
    "    * This suggests that accuracy is not sufficient to assess text quality, and the corpus BLEU helps highlight the model's weaknesses in generating coherent word sequences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wu94sO_w3j-b"
   },
   "source": [
    "# Conclusion\n",
    "The evaluation results show that Transformer has advantages in accuracy and loss, indicating better token prediction accuracy than Vanguard. However, the relatively low Corpus BLEU scores for both models indicate that sentence structure is still far from ideal, even though word-by-word prediction is quite accurate. This means that the syntactic and semantic quality of the sentences are not fully maintained. This situation emphasizes that accuracy and BLEU should not be viewed in isolation, but rather complement each other, accuracy for assessing token prediction, BLEU for assessing sentence fluency. With improved decoding strategies (e.g., beam search) and more sophisticated fine-tuning, BLEU scores can be improved, bringing Transformer closer to being the foundation of modern generative language models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thank You"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
